{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Sharing Demand "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "import calendar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from scipy import stats\n",
    "import missingno as msno\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailyData = pd.read_csv(\"input/train_bike.csv\")\n",
    "dailyData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample of few first rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailyData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailyData.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new columns date, hour, weekday, month from datetime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailyData[\"date\"] = dailyData.datetime.apply(lambda x : x.split()[0])\n",
    "dailyData[\"hour\"] = dailyData.datetime.apply(lambda x : x.split()[1].split(\":\")[0])\n",
    "dailyData[\"weekday\"] = dailyData.date.apply(lambda dateString : calendar.day_name[datetime.strptime(dateString,\"%Y-%m-%d\").weekday()])\n",
    "dailyData[\"month\"] = dailyData.date.apply(lambda dateString : calendar.month_name[datetime.strptime(dateString,\"%Y-%m-%d\").month])\n",
    "dailyData[\"season\"] = dailyData.season.map({1: \"Spring\", 2 : \"Summer\", 3 : \"Fall\", 4 :\"Winter\" })\n",
    "dailyData[\"weather\"] = dailyData.weather.map({1: \" Clear + Few clouds + Partly cloudy + Partly cloudy\",\\\n",
    "                                        2 : \" Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist \", \\\n",
    "                                        3 : \" Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\", \\\n",
    "                                        4 :\" Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \" })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coerce the datatype of season,holiday,workingday and weather to categorical datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryVariableList = [\"hour\",\"weekday\",\"month\",\"season\",\"weather\",\"holiday\",\"workingday\"]\n",
    "for var in categoryVariableList:\n",
    "    dailyData[var] = dailyData[var].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the datetime column as we already extracted useful features from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailyData  = dailyData.drop([\"datetime\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple visualization of variables data type count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTypeDf = pd.DataFrame(dailyData.dtypes.value_counts()).reset_index().rename(columns={\"index\":\"variableType\",0:\"count\"})\n",
    "fig,ax = plt.subplots()\n",
    "fig.set_size_inches(12,5)\n",
    "sn.barplot(data=dataTypeDf,x=\"variableType\",y=\"count\",ax=ax)\n",
    "ax.set(xlabel='variableTypeariable Type', ylabel='Count',title=\"Variables DataType Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(dailyData,figsize=(12,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2,ncols=2)\n",
    "fig.set_size_inches(12, 10)\n",
    "sn.boxplot(data=dailyData,y=\"count\",orient=\"v\",ax=axes[0][0])\n",
    "sn.boxplot(data=dailyData,y=\"count\",x=\"season\",orient=\"v\",ax=axes[0][1])\n",
    "sn.boxplot(data=dailyData,y=\"count\",x=\"hour\",orient=\"v\",ax=axes[1][0])\n",
    "sn.boxplot(data=dailyData,y=\"count\",x=\"workingday\",orient=\"v\",ax=axes[1][1])\n",
    "\n",
    "axes[0][0].set(ylabel='Count',title=\"Box Plot On Count\")\n",
    "axes[0][1].set(xlabel='Season', ylabel='Count',title=\"Box Plot On Count Across Season\")\n",
    "axes[1][0].set(xlabel='Hour Of The Day', ylabel='Count',title=\"Box Plot On Count Across Hour Of The Day\")\n",
    "axes[1][1].set(xlabel='Working Day', ylabel='Count',title=\"Box Plot On Count Across Working Day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailyDataWithoutOutliers = dailyData[np.abs(dailyData[\"count\"]-dailyData[\"count\"].mean())<=(3*dailyData[\"count\"].std())] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Shape Of The Before Ouliers: \",dailyData.shape)\n",
    "print (\"Shape Of The After Ouliers: \",dailyDataWithoutOutliers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatt = dailyData[[\"temp\",\"atemp\",\"casual\",\"registered\",\"humidity\",\"windspeed\",\"count\"]].corr()\n",
    "mask = np.array(corrMatt)\n",
    "mask[np.tril_indices_from(mask)] = False\n",
    "fig,ax= plt.subplots()\n",
    "fig.set_size_inches(20,10)\n",
    "sn.heatmap(corrMatt, mask=mask,vmax=.8, square=True,annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2,ax3) = plt.subplots(ncols=3)\n",
    "fig.set_size_inches(12, 5)\n",
    "sn.regplot(x=\"temp\", y=\"count\", data=dailyData,ax=ax1)\n",
    "sn.regplot(x=\"windspeed\", y=\"count\", data=dailyData,ax=ax2)\n",
    "sn.regplot(x=\"humidity\", y=\"count\", data=dailyData,ax=ax3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Distribution Of Independent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(ncols=2,nrows=2)\n",
    "fig.set_size_inches(12, 10)\n",
    "sn.distplot(dailyData[\"count\"],ax=axes[0][0])\n",
    "stats.probplot(dailyData[\"count\"], dist='norm', fit=True, plot=axes[0][1])\n",
    "sn.distplot(np.log(dailyDataWithoutOutliers[\"count\"]),ax=axes[1][0])\n",
    "stats.probplot(np.log1p(dailyDataWithoutOutliers[\"count\"]), dist='norm', fit=True, plot=axes[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Count Vs (Month,Season,Hour,Weekday,Usertype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2,ax3,ax4)= plt.subplots(nrows=4)\n",
    "fig.set_size_inches(12,20)\n",
    "sortOrder = [\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"]\n",
    "hueOrder = [\"Sunday\",\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\"]\n",
    "\n",
    "monthAggregated = pd.DataFrame(dailyData.groupby(\"month\")[\"count\"].mean()).reset_index()\n",
    "monthSorted = monthAggregated.sort_values(by=\"count\",ascending=False)\n",
    "sn.barplot(data=monthSorted,x=\"month\",y=\"count\",ax=ax1,order=sortOrder)\n",
    "ax1.set(xlabel='Month', ylabel='Avearage Count',title=\"Average Count By Month\")\n",
    "\n",
    "hourAggregated = pd.DataFrame(dailyData.groupby([\"hour\",\"season\"],sort=True)[\"count\"].mean()).reset_index()\n",
    "sn.pointplot(x=hourAggregated[\"hour\"], y=hourAggregated[\"count\"],hue=hourAggregated[\"season\"], data=hourAggregated, join=True,ax=ax2)\n",
    "ax2.set(xlabel='Hour Of The Day', ylabel='Users Count',title=\"Average Users Count By Hour Of The Day Across Season\",label='big')\n",
    "\n",
    "hourAggregated = pd.DataFrame(dailyData.groupby([\"hour\",\"weekday\"],sort=True)[\"count\"].mean()).reset_index()\n",
    "sn.pointplot(x=hourAggregated[\"hour\"], y=hourAggregated[\"count\"],hue=hourAggregated[\"weekday\"],hue_order=hueOrder, data=hourAggregated, join=True,ax=ax3)\n",
    "ax3.set(xlabel='Hour Of The Day', ylabel='Users Count',title=\"Average Users Count By Hour Of The Day Across Weekdays\",label='big')\n",
    "\n",
    "hourTransformed = pd.melt(dailyData[[\"hour\",\"casual\",\"registered\"]], id_vars=['hour'], value_vars=['casual', 'registered'])\n",
    "hourAggregated = pd.DataFrame(hourTransformed.groupby([\"hour\",\"variable\"],sort=True)[\"value\"].mean()).reset_index()\n",
    "sn.pointplot(x=hourAggregated[\"hour\"], y=hourAggregated[\"value\"],hue=hourAggregated[\"variable\"],hue_order=[\"casual\",\"registered\"], data=hourAggregated, join=True,ax=ax4)\n",
    "ax4.set(xlabel='Hour Of The Day', ylabel='Users Count',title=\"Average Users Count By Hour Of The Day Across User Type\",label='big')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values Analysis In Windspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = pd.read_csv(\"input/train_bike.csv\")\n",
    "dataTest = pd.read_csv(\"input/test_bike.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataTrain.append(dataTest)\n",
    "data.reset_index(inplace=True)\n",
    "data.drop('index',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"date\"] = data.datetime.apply(lambda x : x.split()[0])\n",
    "data[\"hour\"] = data.datetime.apply(lambda x : x.split()[1].split(\":\")[0]).astype(\"int\")\n",
    "data[\"year\"] = data.datetime.apply(lambda x : x.split()[0].split(\"-\")[0])\n",
    "data[\"weekday\"] = data.date.apply(lambda dateString : datetime.strptime(dateString,\"%Y-%m-%d\").weekday())\n",
    "data[\"month\"] = data.date.apply(lambda dateString : datetime.strptime(dateString,\"%Y-%m-%d\").month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "dataWind0 = data[data[\"windspeed\"]==0]\n",
    "dataWindNot0 = data[data[\"windspeed\"]!=0]\n",
    "rfModel_wind = RandomForestRegressor()\n",
    "windColumns = [\"season\",\"weather\",\"humidity\",\"month\",\"temp\",\"year\",\"atemp\"]\n",
    "rfModel_wind.fit(dataWindNot0[windColumns], dataWindNot0[\"windspeed\"])\n",
    "\n",
    "wind0Values = rfModel_wind.predict(X= dataWind0[windColumns])\n",
    "dataWind0[\"windspeed\"] = wind0Values\n",
    "data = dataWindNot0.append(dataWind0)\n",
    "data.reset_index(inplace=True)\n",
    "data.drop('index',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalFeatureNames = [\"season\",\"holiday\",\"workingday\",\"weather\",\"weekday\",\"month\",\"year\",\"hour\"]\n",
    "numericalFeatureNames = [\"temp\",\"humidity\",\"windspeed\",\"atemp\"]\n",
    "dropFeatures = ['casual',\"count\",\"datetime\",\"date\",\"registered\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in categoricalFeatureNames:\n",
    "    data[var] = data[var].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = data[pd.notnull(data['count'])].sort_values(by=[\"datetime\"])\n",
    "dataTest = data[~pd.notnull(data['count'])].sort_values(by=[\"datetime\"])\n",
    "datetimecol = dataTest[\"datetime\"]\n",
    "yLabels = dataTrain[\"count\"]\n",
    "yLablesRegistered = dataTrain[\"registered\"]\n",
    "yLablesCasual = dataTrain[\"casual\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain  = dataTrain.drop(dropFeatures,axis=1)\n",
    "dataTest  = dataTest.drop(dropFeatures,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSLE Scorer Root Mean Square Logarithmic Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y, y_,convertExp=True):\n",
    "    if convertExp:\n",
    "        y = np.exp(y),\n",
    "        y_ = np.exp(y_)\n",
    "    log1 = np.nan_to_num(np.array([np.log(v + 1) for v in y]))\n",
    "    log2 = np.nan_to_num(np.array([np.log(v + 1) for v in y_]))\n",
    "    calc = (log1 - log2) ** 2\n",
    "    return np.sqrt(np.mean(calc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# Initialize logistic regression model\n",
    "lModel = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "yLabelsLog = np.log1p(yLabels)\n",
    "lModel.fit(X = dataTrain,y = yLabelsLog)\n",
    "\n",
    "# Make predictions\n",
    "preds = lModel.predict(X= dataTrain)\n",
    "print (\"RMSLE Value For Linear Regression: \",rmsle(np.exp(yLabelsLog),np.exp(preds),False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_m_ = Ridge()\n",
    "ridge_params_ = { 'max_iter':[3000],'alpha':[0.1, 1, 2, 3, 4, 10, 30,100,200,300,400,800,900,1000]}\n",
    "rmsle_scorer = metrics.make_scorer(rmsle, greater_is_better=False)\n",
    "grid_ridge_m = GridSearchCV( ridge_m_,\n",
    "                          ridge_params_,\n",
    "                          scoring = rmsle_scorer,\n",
    "                          cv=5)\n",
    "yLabelsLog = np.log1p(yLabels)\n",
    "grid_ridge_m.fit( dataTrain, yLabelsLog )\n",
    "preds = grid_ridge_m.predict(X= dataTrain)\n",
    "print (grid_ridge_m.best_params_)\n",
    "print (\"RMSLE Value For Ridge Regression: \",rmsle(np.exp(yLabelsLog),np.exp(preds),False))\n",
    "\n",
    "fig,ax= plt.subplots()\n",
    "fig.set_size_inches(12,5)\n",
    "df = pd.DataFrame(grid_ridge_m.grid_scores_)\n",
    "df[\"alpha\"] = df[\"parameters\"].apply(lambda x:x[\"alpha\"])\n",
    "df[\"rmsle\"] = df[\"mean_validation_score\"].apply(lambda x:-x)\n",
    "sn.pointplot(data=df,x=\"alpha\",y=\"rmsle\",ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_m_ = Lasso()\n",
    "\n",
    "alpha  = 1/np.array([0.1, 1, 2, 3, 4, 10, 30,100,200,300,400,800,900,1000])\n",
    "lasso_params_ = { 'max_iter':[3000],'alpha':alpha}\n",
    "\n",
    "grid_lasso_m = GridSearchCV( lasso_m_,lasso_params_,scoring = rmsle_scorer,cv=5)\n",
    "yLabelsLog = np.log1p(yLabels)\n",
    "grid_lasso_m.fit( dataTrain, yLabelsLog )\n",
    "preds = grid_lasso_m.predict(X= dataTrain)\n",
    "print (grid_lasso_m.best_params_)\n",
    "print (\"RMSLE Value For Lasso Regression: \",rmsle(np.exp(yLabelsLog),np.exp(preds),False))\n",
    "\n",
    "fig,ax= plt.subplots()\n",
    "fig.set_size_inches(12,5)\n",
    "df = pd.DataFrame(grid_lasso_m.grid_scores_)\n",
    "df[\"alpha\"] = df[\"parameters\"].apply(lambda x:x[\"alpha\"])\n",
    "df[\"rmsle\"] = df[\"mean_validation_score\"].apply(lambda x:-x)\n",
    "sn.pointplot(data=df,x=\"alpha\",y=\"rmsle\",ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfModel = RandomForestRegressor(n_estimators=100)\n",
    "yLabelsLog = np.log1p(yLabels)\n",
    "rfModel.fit(dataTrain,yLabelsLog)\n",
    "preds = rfModel.predict(X= dataTrain)\n",
    "print (\"RMSLE Value For Random Forest: \",rmsle(np.exp(yLabelsLog),np.exp(preds),False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbm = GradientBoostingRegressor(n_estimators=4000,alpha=0.01); ### Test 0.41\n",
    "yLabelsLog = np.log1p(yLabels)\n",
    "gbm.fit(dataTrain,yLabelsLog)\n",
    "preds = gbm.predict(X= dataTrain)\n",
    "print (\"RMSLE Value For Gradient Boost: \",rmsle(np.exp(yLabelsLog),np.exp(preds),False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsTest = gbm.predict(X= dataTest)\n",
    "fig,(ax1,ax2)= plt.subplots(ncols=2)\n",
    "fig.set_size_inches(12,5)\n",
    "sn.distplot(yLabels,ax=ax1,bins=50)\n",
    "sn.distplot(np.exp(predsTest),ax=ax2,bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"datetime\": datetimecol,\n",
    "        \"count\": [max(0, x) for x in np.exp(predsTest)]\n",
    "    })\n",
    "submission.to_csv('output/bike_predictions_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
